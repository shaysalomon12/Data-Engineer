{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from Excel and display using pandas\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('c:\\\\aaa\\\\titanic3.csv') \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from SQL Server\n",
    "import pyodbc\n",
    "import sqlalchemy as sa\n",
    "import pandas as pd\n",
    "from sqlalchemy.engine import URL       # To support pandas\n",
    "from sqlalchemy import create_engine    # To support pandas\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# server parameters\n",
    "server = 'BSQL' \n",
    "database = 'DBA' \n",
    "username = 'naya5' \n",
    "password = '9451P9Qt%&h!'\n",
    "conn_string =  'DRIVER={SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password\n",
    "\n",
    "conn = pyodbc.connect(conn_string)\n",
    "conn_url = URL.create(\"mssql+pyodbc\", query={\"odbc_connect\": conn_string}) # To support pandas\n",
    "\n",
    "query = (\"select \"\n",
    "            \"server, \"\n",
    "            \"database_name, \"\n",
    "            \"last_successful_log_restore, \"\n",
    "            \"datediff(minute, last_successful_log_restore, getdate()) as minutes_since_last_restored \"\n",
    "        \"from \"\n",
    "        \"( \"\n",
    "        \"select \"\n",
    "            \"@@SERVERNAME as Server, \"\n",
    "            \"b.database_name, \"\n",
    "            \"max(a.restore_date) last_successful_log_restore \"\n",
    "        \"from msdb..restorehistory a \"\n",
    "        \"INNER JOIN msdb..backupset b ON a.backup_set_id = b.backup_set_id \"\n",
    "        \"where  \"\n",
    "            \"b.database_name IN ('Cetentities','cetgroups3','Common','Lms','Cetstore') \"\n",
    "        \"group by b.database_name \"\n",
    "        \") a \"\n",
    "        )\n",
    "\n",
    "# --- Print to terminal ---\n",
    "#cursor = conn.cursor()\n",
    "#cursor.execute(query)\n",
    "\n",
    "#for i in cursor:\n",
    "#    print(i)\n",
    "# --- Print to terminal ---\n",
    "\n",
    "# --- Print using pandas dataframe ---\n",
    "engine = sa.create_engine(conn_url)\n",
    "df = pd.read_sql(query, engine)\n",
    "df.head()\n",
    "# --- Print using pandas dataframe ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from MongoDB\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "# MongoDB connection string\n",
    "myClient = MongoClient(\n",
    "    host='172.17.30.23:27017',\n",
    "    serverSelectionTimeoutMS=3000,\n",
    "    username=\"sa\",\n",
    "    password=\"global11!\"\n",
    ")\n",
    "\n",
    "# Select Database and Collection\n",
    "myDB = myClient[\"test\"]\n",
    "myCollection = myDB[\"demo\"]\n",
    "\n",
    "# Query collection test.demo for number = '1000-10'\n",
    "myQuery = {\n",
    "        \"balance\" : {\n",
    "            \"$gte\" : 20,\n",
    "            \"$lte\" : 30\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Run query (using sort and limit)\n",
    "myDoc = myCollection.find(myQuery).sort(\"balance\", -1).limit(10)  # -1 descending\n",
    "\n",
    "# Print using Pandas and tabulate\n",
    "entries = list(myDoc)\n",
    "df = pd.DataFrame(entries, columns = ['id', 'number', 'currency', 'balance'])\n",
    "# print(tabulate(df, headers='keys', tablefmt='psql'))\n",
    "\n",
    "# Print using pandas only (will work only inside a notebook)\n",
    "df\n",
    "\n",
    "# Print the results to the console\n",
    "# for x in myDoc:\n",
    "#    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Graphs\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(ncols=5, figsize=(30,5))\n",
    "sns.violinplot(x=\"survived\", y=\"age\", hue=\"sex\", data=data, ax=axs[0])\n",
    "sns.pointplot(x=\"sibsp\", y=\"survived\", hue=\"sex\", data=data, ax=axs[1])\n",
    "sns.pointplot(x=\"parch\", y=\"survived\", hue=\"sex\", data=data, ax=axs[2])\n",
    "sns.pointplot(x=\"pclass\", y=\"survived\", hue=\"sex\", data=data, ax=axs[3])\n",
    "sns.violinplot(x=\"survived\", y=\"fare\", hue=\"sex\", data=data, ax=axs[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Shipping bar graph from SQL Server\n",
    "import pyodbc\n",
    "import sqlalchemy as sa\n",
    "import pandas as pd\n",
    "from sqlalchemy.engine import URL       # To support pandas\n",
    "from sqlalchemy import create_engine    # To support pandas\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# server parameters\n",
    "server = 'BSQL' \n",
    "database = 'DBA' \n",
    "username = 'naya5' \n",
    "password = '9451P9Qt%&h!'\n",
    "conn_string =  'DRIVER={SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password\n",
    "\n",
    "conn = pyodbc.connect(conn_string)\n",
    "conn_url = URL.create(\"mssql+pyodbc\", query={\"odbc_connect\": conn_string}) # To support pandas\n",
    "\n",
    "query = (\"select \"\n",
    "            # \"server, \"\n",
    "            \"database_name, \"\n",
    "            \"db_name, \"\n",
    "            # \"last_successful_log_restore, \"\n",
    "            \"datediff(minute, last_successful_log_restore, getdate()) as minutes_since_last_restored \"\n",
    "        \"from \"\n",
    "        \"( \"\n",
    "        \"select \"\n",
    "            # \"@@SERVERNAME as Server, \"\n",
    "            \"b.database_name, \"\n",
    "            \"b.database_name as db_name, \"\n",
    "            \"max(a.restore_date) last_successful_log_restore \"\n",
    "        \"from msdb..restorehistory a \"\n",
    "        \"INNER JOIN msdb..backupset b ON a.backup_set_id = b.backup_set_id \"\n",
    "        \"where  \"\n",
    "            \"b.database_name IN ('Cetentities','cetgroups3','Common','Lms','Cetstore') \"\n",
    "        \"group by b.database_name \"\n",
    "        \") a \"\n",
    "        )\n",
    "\n",
    "# --- Print to terminal ---\n",
    "#cursor = conn.cursor()\n",
    "#cursor.execute(query)\n",
    "\n",
    "#for i in cursor:\n",
    "#    print(i)\n",
    "# --- Print to terminal ---\n",
    "\n",
    "# --- Print bar graph using pandas dataframe ---\n",
    "engine = sa.create_engine(conn_url)\n",
    "df = pd.read_sql(query, engine)\n",
    "\n",
    "t=df.groupby(['database_name', 'db_name'])['minutes_since_last_restored'].sum().unstack('database_name').fillna(0)\n",
    "t.plot(kind='bar', stacked=True)\n",
    "\n",
    "plt.title('BSQL Log Shipping Sync Time')\n",
    "plt.xlabel('Database')\n",
    "plt.ylabel('Minutes Since Last Transaction Log was Restored')\n",
    "\n",
    "# --- Print bar graph using pandas dataframe ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databases size bar graph from MongoDB\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# MongoDB connection string\n",
    "myClient = MongoClient(\n",
    "    host='172.17.30.23:27017',\n",
    "    serverSelectionTimeoutMS=3000,\n",
    "    username=\"sa\",\n",
    "    password=\"global11!\"\n",
    ")\n",
    "\n",
    "# Set pandas dataframe with 2 columns\n",
    "df = pd.DataFrame(columns=['database_name','sizeOnDisk'])\n",
    "\n",
    "# Iterate over all databases and populate the dataframe\n",
    "for dbname in enumerate(myClient.list_databases()):\n",
    "    # print(\"database name is : \",dbname) # This is the original tupple\n",
    "    database_name = dbname[1].get('name')\n",
    "    size_on_disk  = dbname[1].get('sizeOnDisk')\n",
    "    # print(\"database: \", database_name, \", Size: \", round(size_on_disk/1024/1024/1024,2), ' GB')\n",
    "    \n",
    "    # Populate the dataframe\n",
    "    record = {'database': database_name, 'sizeOnDisk': size_on_disk }\n",
    "\n",
    "    entry = pd.DataFrame.from_dict({\n",
    "     \"database_name\": [database_name],\n",
    "     \"sizeOnDisk\":  [round(size_on_disk/1024/1024/1024,2)]\n",
    "    })\n",
    "    df = pd.concat([df, entry], ignore_index=True)\n",
    "\n",
    "# Display as graph\n",
    "t=df.groupby(['database_name'])['sizeOnDisk'].sum().fillna(0)\n",
    "t.plot(kind='bar', stacked=False)\n",
    "\n",
    "plt.title('MongoDB Databases Size')\n",
    "plt.xlabel('Database')\n",
    "plt.ylabel('Size On Disk (GB)')\n",
    "\n",
    "# df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "639fd59d79ea090b880e7d610bf41c56f8a449bca7d989cb79aa4d478f53a391"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
